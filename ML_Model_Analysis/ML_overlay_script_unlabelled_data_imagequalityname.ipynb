{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a811f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, os, pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97e7df",
   "metadata": {},
   "source": [
    "This code reads the slice data for the inference files, and labels the score according to what the model recognised that section as. \n",
    "Therefore, it allows a quick visual check on what features were being recognised by the model to try and evaluate weaknesses in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a1a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to the directory, and define the files of that contain the scores for each slice\n",
    "os.chdir('E:/5.Machine Learning/7.Unlabelled Data Test/ML Categorised/Quality Cut-off 83.125/')\n",
    "\n",
    "image_locs='E:/5.Machine Learning/7.Unlabelled Data Test/ML Categorised/Quality Cut-off 83.125/'\n",
    "\n",
    "segment_txtfiles=['Unlabelled_data_repeat-S2-A03__results_02.txt','Unlabelled_data_repeat-S3-A01__results_02.txt']\n",
    "segment_px_dimensions=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fead3de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check the crop dimensions are correct. \u001b[39;00m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0_2021-01-18 - 11.04.16 Frame 012 Trace 2450um along_pixelsquare.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m shape\u001b[38;5;241m=\u001b[39m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      4\u001b[0m crop_img \u001b[38;5;241m=\u001b[39m image[\u001b[38;5;241m56\u001b[39m:\u001b[38;5;241m1056\u001b[39m,\u001b[38;5;241m65\u001b[39m:\u001b[38;5;241m1065\u001b[39m]\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m,crop_img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Check the crop dimensions are correct. \n",
    "image = cv2.imread('0.0_2021-01-18 - 11.04.16 Frame 012 Trace 2450um along_pixelsquare.jpg')\n",
    "shape=image.shape\n",
    "crop_img = image[56:1056,65:1065]\n",
    "cv2.imshow('hello',crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c014a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256\n"
     ]
    }
   ],
   "source": [
    "print(shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653eeefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_imagename(image_name):\n",
    "    if image_name[0]=='/':\n",
    "        image_name=image_name[1:]     #Gets rid of the \"/\" at the start of the filename for the norm datasets.\n",
    "    image_name=image_name.replace('_',' ')    #Undoes the underscoring of names done for AWS, to match the image names in folder\n",
    "    \n",
    "    image_name=image_name.rsplit(' ', 2)[0]     #removes the \"1000 pixel square\" to be replaced with ones with underscores\n",
    "    \n",
    "    original_imagename=image_name+' along_pixelsquare.jpg'    #creates the filename ending as per the original images\n",
    "    \n",
    "    return original_imagename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f00921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_transparent(background, overlay, x, y, alpha):\n",
    "    #https://stackoverflow.com/questions/40895785/using-opencv-to-overlay-transparent-image-onto-another-image\n",
    "    \n",
    "    background_width = background.shape[1]\n",
    "    background_height = background.shape[0]\n",
    "    \n",
    "    #If coordinates given go off the image coordinates\n",
    "    if x >= background_width or y >= background_height:\n",
    "        print('coordinates exceeded limits for',x,y)\n",
    "        return background\n",
    "\n",
    "    h, w = overlay.shape[0], overlay.shape[1]\n",
    "\n",
    "    if x + w > background_width:\n",
    "        w = background_width - x\n",
    "        #Crops any region of the width of the overlay that will go past background coords\n",
    "        overlay = overlay[:, :w]\n",
    "\n",
    "    if y + h > background_height:\n",
    "        h = background_height - y\n",
    "        #Crops any region of the height of the overlay that will go past background coords\n",
    "        overlay = overlay[:h]\n",
    "    \n",
    "    #Figure out what this bit means... something to do with colour.\n",
    "    if overlay.shape[2] < 4:\n",
    "        overlay = np.concatenate(\n",
    "            [overlay,np.ones((overlay.shape[0], overlay.shape[1], 1), dtype = overlay.dtype) * 255],\n",
    "            axis = 2)\n",
    "\n",
    "    overlay_image = overlay[..., :3]\n",
    "    mask = overlay[..., 3:] / 255.0\n",
    "    \n",
    "    #my bodgeline below. \n",
    "    mask=alpha\n",
    "    background[y:y+h, x:x+w] = (1 - mask) * background[y:y+h, x:x+w] + mask * overlay_image\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2879d2c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n"
     ]
    }
   ],
   "source": [
    "# Main code to label the image files from inference. Check the location. \n",
    "#old_image_loc=\"\"\n",
    "os.chdir('E:/5.Machine Learning/7.Unlabelled Data Test/') # Location of the segment_txtfiles results\n",
    "ful_results=['Unlabelled_data_repeat-S2-A03__full_results_02.txt', 'Unlabelled_data_repeat-S3-A01__full_results_02.txt']\n",
    "imagequal_data1 = pd.read_csv(ful_results[0], sep=\" \") \n",
    "imagequal_data2 = pd.read_csv(ful_results[1], sep=\" \") \n",
    "imagequal = [imagequal_data1, imagequal_data2]\n",
    "\n",
    "imagequaldata = pd.concat(imagequal, ignore_index=True)\n",
    "\n",
    "for txtfile in segment_txtfiles:\n",
    "    os.chdir('E:/5.Machine Learning/7.Unlabelled Data Test/') # Location of the segment_txtfiles results\n",
    "    data = pd.read_csv(txtfile, sep=\" \") # Read the data as a pandas dataframe\n",
    "    new_file_row=data.iloc[::16, :]   # Sets the limit to define a new file. For 4x4 slices, this would be 16. \n",
    "    counter=0\n",
    "    for image_index, image_row in new_file_row.iterrows():\n",
    "        imagename = image_row['Filename'] #Gets the filename from the txt file\n",
    "        original_imagename = get_old_imagename(imagename) #Finds the image filename using the pre-defined function above.\n",
    "        #print(original_imagename)\n",
    "        imagequality_score=9999999\n",
    "        #Find the image quality score for the associated frame\n",
    "        for index, row in imagequaldata.iterrows():  \n",
    "            if row['Filename']==imagename:\n",
    "                imagequality_score=row['Rekognition']\n",
    "                \n",
    "        if imagequality_score==9999999:\n",
    "            print('Image quality not found for',imagename)\n",
    "            break\n",
    "\n",
    "        imagequality_name=str(imagequality_score)+'_'+original_imagename\n",
    "\n",
    "        #Find the image in the categories inference image directory folders (walking between FP/FN/TP/TN)\n",
    "        for root, dirs, files in os.walk(image_locs):\n",
    "            if imagequality_name in files:\n",
    "                #print(\"root = \",root)\n",
    "                old_image_loc= os.path.join(root, imagequality_name)\n",
    "                old_image_loc=old_image_loc.replace(\"\\\\\",\"/\")\n",
    "\n",
    "        oldpath=os.path.dirname(old_image_loc)\n",
    "        os.chdir(oldpath)\n",
    "\n",
    "        # load the image\n",
    "        image = cv2.imread(imagequality_name) \n",
    "        #height, width, channels = image.shape\n",
    "        #print (height, width, channels)          #1064 1248 3\n",
    "        #crop_img = image[60:1060, 68:1068]       #Y coords and X coords of the AFM image. \n",
    "        \n",
    "        #Identify the 16 segments' data for this image\n",
    "        slice_rows=data[image_index : image_index+16]\n",
    "        \n",
    "        # create a copy of the original image -- for the final output image\n",
    "        output = image.copy()\n",
    "        # create overlay copy of the original image -- one for the overlay and one for the final output image\n",
    "        overlay = image.copy()\n",
    "        #txtoverlay = image.copy()\n",
    "        \n",
    "        #For each of the 16 slices:\n",
    "        for slice_index, slice_row in slice_rows.iterrows():  \n",
    "            rekog_anom_score =  slice_row['Rekognition_anom']\n",
    "            #print(type(rekog_anom_score))\n",
    "            if rekog_anom_score>0.1:\n",
    "                segment_no= slice_row['Section']\n",
    "                ##Check the values at start to ensure they correspond to the starting pixel crop locations.\n",
    "                y_coord=56+(int(segment_no[0])*segment_px_dimensions)\n",
    "                x_coord=65+(int(segment_no[2])*segment_px_dimensions)\n",
    "\n",
    "                y_end_coord=56+((int(segment_no[0])+1)*segment_px_dimensions)\n",
    "                x_end_coord=65+((int(segment_no[2])+1)*segment_px_dimensions)\n",
    "\n",
    "                # draw a rectangle in the image\n",
    "                # represents the top left corner of rectangle\n",
    "                start_point = (x_coord+1, y_coord+1)\n",
    "                # represents the bottom right corner of rectangle\n",
    "                end_point = (x_end_coord-1, y_end_coord-1)\n",
    "\n",
    "                #Create an overlay for that segment\n",
    "                if slice_row['Label']=='anomaly':\n",
    "                    color = (0, 0, 255)      # Red color in BGR\n",
    "                    alpha=rekog_anom_score\n",
    "                else:\n",
    "                    color = (0, 215, 255)    # Orange\n",
    "                    alpha=rekog_anom_score+0.3\n",
    "                    \n",
    "                #cv2.rectangle(overlay, start_point, end_point, color, -1) #-1 fills rectangle\n",
    "                cv2.rectangle(overlay, start_point, end_point, color, 2) #border of rectangle only\n",
    "                cv2.putText(overlay, str(rekog_anom_score), (start_point[0]+75, start_point[1]+125), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "                \n",
    "\n",
    "                # apply the overlay\n",
    "                #output=cv2.addWeighted(overlay, alpha, output, 1-alpha, 0, output)\n",
    "                crop_overlay = overlay[start_point[1]:end_point[1]+1, start_point[0]:end_point[0]+1]\n",
    "                output=overlay_transparent(output, crop_overlay, start_point[0], start_point[1], alpha)   \n",
    "\n",
    "        \n",
    "        # show the output image\n",
    "        #small_output = cv2.resize(output, (int(1248 *0.75), int(1064*0.75)))\n",
    "        #cv2.imshow(str(counter)+' - '+original_imagename[:-4], small_output)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        \n",
    "        counter+=1\n",
    "        if str(counter).endswith('0'):\n",
    "            print(counter)\n",
    "#         if counter==5:\n",
    "#            break\n",
    "        \n",
    "        # Saving the image\n",
    "        labelled_filename= str(imagequality_score)+'_'+original_imagename[:-4]+'_rek-score1.jpg'\n",
    "        cv2.imwrite(labelled_filename, output)\n",
    "    #break   ##Delete this line when doing both files!!!!!!!\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fb48c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064 1248 3\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('E:/6.Images for ML Inference/Inference Results - 1000x1000 inference7/ML Categorised/')\n",
    "2021-05-11 - 10.35.50 Frame 004 Trace 25um along_1000_pixelsquare\n",
    "# load the image\n",
    "#image = cv2.imread(\"2021-05-11 - 10.35.50 Frame 036 Trace 225um along_1000_pixelsquare.jpg\")\n",
    "\n",
    "#height, width, channels = image.shape\n",
    "#print (height, width, channels)\n",
    "\n",
    "#crop_img = image[60:1060, 68:1068] #X coords and Y coords of the AFM image. \n",
    "#cv2.imshow(\"cropped\", crop_img)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa7a7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the alpha transparency values\n",
    "#for alpha in np.arange(0, 1.05, 0.05)[::-1]:\n",
    "    \n",
    "    # create two copies of the original image -- one for the overlay and one for the final output image\n",
    "  #  overlay = image.copy()\n",
    "  #  output = image.copy()\n",
    "    \n",
    "    # draw a red rectangle in the image\n",
    "    # represents the top left corner of rectangle\n",
    " #   start_point = (5, 5)\n",
    "    # represents the bottom right corner of rectangle\n",
    "  #  end_point = (220, 220)\n",
    "    \n",
    "    # Red color in BGR\n",
    " #   color = (0, 0, 255)\n",
    "    #cv2.rectangle(overlay, start_point, end_point, color, -1) #-1 fills rectangle\n",
    " #   cv2.rectangle(overlay, start_point, end_point, color, 3) #border of rectangle only\n",
    "\n",
    "    #cv2.putText(overlay, \"PyImageSearch: alpha={}\".format(alpha), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n",
    "    \n",
    "    # apply the overlay\n",
    "  #  cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n",
    "    \n",
    "    # show the output image\n",
    "    #print(\"alpha={}, beta={}\".format(alpha, 1 - alpha))\n",
    "   # cv2.imshow(\"Output\"+str(alpha), output)\n",
    "    #cv2.waitKey(0)\n",
    "   # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90363d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving the image\n",
    "#cv2.imwrite(filename, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
